{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a8182d5b",
   "metadata": {},
   "source": [
    "# Формирование датасета с mel-спектрограммами из датасета HiFiTTS (состоящего из аудио-записей в формате .flac) для обучения модели Tacotron2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "259433a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Импорты\n",
    "import sys\n",
    "sys.path.append('tacotron2/')\n",
    "from tacotron2.hparams import create_hparams\n",
    "from tacotron2.layers import TacotronSTFT\n",
    "import json\n",
    "import pandas as pd\n",
    "import os\n",
    "from io import BytesIO\n",
    "from scipy.io.wavfile import write"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4ebacc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Директория расположения датасета\n",
    "hifitts_path = './hi_fi_tts_v0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85816922",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Гиперпараметры\n",
    "hp = create_hparams()\n",
    "\n",
    "# Оконное преобразование Фурье\n",
    "# Акустическая модель (tacotron2) и вокодер (waveglow) должны быть обучены на спектрограммах сформированных \n",
    "# с одинаковыми параметрами модуля STFT\n",
    "stft = TacotronSTFT(\n",
    "    hp.filter_length, \n",
    "    hp.hop_length, \n",
    "    hp.win_length,\n",
    "    hp.n_mel_channels, \n",
    "    hp.sampling_rate, \n",
    "    hp.mel_fmin,\n",
    "    hp.mel_fmax\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cdab6c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_json(json_path):\n",
    "    '''\n",
    "    Функция отвечает за считывание файлов manifest.json\n",
    "    '''\n",
    "    dataset_type = json_path.split('_')[-1].replace('.json', '')\n",
    "    with open(json_path, encoding='utf-8') as f:\n",
    "        cond = \"[\" + f.read().replace(\"}\\n{\", \"},\\n{\") + \"]\"\n",
    "        json_data = json.loads(cond)\n",
    "        for item in json_data:\n",
    "            item['dataset_type'] = dataset_type\n",
    "    return json_data\n",
    "\n",
    "def flac_to_mel(load_flac_path, save_mel_path, dataset_type, txt_line):\n",
    "    '''\n",
    "    Функция формирует мел-спектрограмму из аудио-файла и сохраняет её\n",
    "    '''\n",
    "    \n",
    "    # Считываем аудио-данные и частоту дискретизации файла (.flac, 44100Hz, pcm-f)\n",
    "    flac_data, sample_rate = librosa.load(load_flac_path)\n",
    "    \n",
    "    # Формируем мел-спектрограмму\n",
    "    melspec_1 = librosa.feature.melspectrogram(y=flac_data,sr=sample_rate)\n",
    "    \n",
    "    # Отсекаем слишком большие спектрограммы\n",
    "    # для nvidia tesla t4 16gb с размером спектрограммы <1000 получалось установить размер батча=64\n",
    "    # иначе может вылетать ошибка pytorch о переполнении памяти gpu, и придется уменьшать размер батча\n",
    "    # зависит от gpu на которой будут происходить вычисления\n",
    "    if melspec_1.shape[1] >= 1000:\n",
    "        return False\n",
    "    \n",
    "    # Записываем информационную строку о текущем элементе в тексовый файл для обучения/валидации модели\n",
    "    with open('./hifitts/' + dataset_type + '.txt', 'a') as f:\n",
    "        f.write(txt_line)\n",
    "        \n",
    "    # Формируем новое аудио для записи в память\n",
    "    audio = librosa.feature.inverse.mel_to_audio(melspec_1, sr=sample_rate)\n",
    "    \n",
    "    # Буфер памяти (что-бы не сохранять локально)\n",
    "    buf = BytesIO()\n",
    "    \n",
    "    # Запись файла с другими параметрами, нежели были изначально\n",
    "    # Необходимо, т.к. используется вокодер обученный на аудио с частотой дискретизации = 22050Hz\n",
    "    # Так-же метод write модуля scipy считывает только wav формат\n",
    "    # (считанные данные из flac файлов библиотеками librosa и soundfile, почему-то некорректно преобразовывались в \n",
    "    # mel-спектрограммы модулем stft)\n",
    "    write(buf, sample_rate, audio)\n",
    "    buffered_audio = buf.getvalue()\n",
    "    buf.close()\n",
    "    \n",
    "    # Считываем аудио-данные и частоту дискретизации файла (.wav, 22050Hz, pcm-s)\n",
    "    buf_data, sr = sf.read(buffered_audio)\n",
    "    \n",
    "    # Преобразовываем в тензор\n",
    "    floated_data = torch.FloatTensor(buf_data.astype(np.float32))\n",
    "    \n",
    "    # Формирование мел-спектрограммы\n",
    "    norm_data = floated_data / hp.max_wav_value\n",
    "    norm_data = norm_data.unsqueeze(0)\n",
    "    norm_data = torch.autograd.Variable(norm_data, requires_grad=False)\n",
    "    melspec_2 = stft.mel_spectrogram(norm_data)\n",
    "    melspec_2 = torch.squeeze(melspec_2, 0)\n",
    "    \n",
    "    # Сохранение файла\n",
    "    np.save(save_mel_path, melspec_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5747ae3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Формирование единого датафрейма по всем manifest-файлам .json \n",
    "manifests = [manifest for manifest in os.listdir(hifitts_path) if 'manifest' in manifest]\n",
    "manifest_paths = [f'{hifitts_path}/{manifest}' for manifest in manifests]\n",
    "manifest_jsons = [read_json(manifest_path) for manifest_path in manifest_paths]\n",
    "manifest_dfs = [pd.DataFrame(manifest_json) for manifest_json in manifest_jsons]\n",
    "manifests_df = pd.concat(manifest_dfs, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e62b69a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = manifests_df.reset_index(drop=True).copy()\n",
    "\n",
    "# Формирование колонки с нормализованным id диктора (от 0 до 9)\n",
    "df['reader_id'] = df['audio_filepath'].apply(lambda x: x.split('/')[1].split('_')[0])\n",
    "readers_list = [reader_id for reader_id in df.reader_id.unique()]\n",
    "readers_dict = {reader_id: str(readers_list.index(reader_id)) for reader_id in readers_list}\n",
    "df['reader_id_norm'] = df['reader_id'].apply(lambda x: readers_dict[x])\n",
    "\n",
    "# Формирование строки текстового файла по которому модель будет обучаться/валидироваться\n",
    "df['mel_path'] = 'mels/' + df.index.astype('string') + '_' + df['dataset_type'] + '_' + df['reader_id']\n",
    "df['txt_line'] = df['mel_path'] + '|' + df['text'] + '|' + df['reader_id_norm'] + '\\n'\n",
    "\n",
    "# Оставляем только необходимые колонки\n",
    "df = df[['dataset_type', 'reader_id', 'reader_id_norm', 'text', 'audio_filepath', 'mel_path', 'txt_line']]\n",
    "\n",
    "# Оставляем только тестовую и тренеровочную выборки\n",
    "df = df[df['dataset_type'] != 'dev']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8145e139",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создание директории для записи файлов\n",
    "os.mkdir('./hifitts')\n",
    "os.mkdir('./hifitts/mels')\n",
    "\n",
    "tmp_df = df.copy()\n",
    "\n",
    "# Формирование колонки со \"строкой-параметрами\" для передачи в виде аргумента в функцию\n",
    "tmp_df['line_for_create_mel'] = \\\n",
    "    tmp_df['audio_filepath'] + '&' + \\\n",
    "    tmp_df['mel_path'] + '&' + \\\n",
    "    tmp_df['dataset_type'] + '&' + \\\n",
    "    tmp_df['txt_line']\n",
    "\n",
    "# Создание мелспектрограмм\n",
    "tmp_df['line_for_create_mel'].apply(lambda x: flac_to_mel(\n",
    "    x.split('&')[0], \n",
    "    x.split('&')[1], \n",
    "    x.split('&')[2],\n",
    "    x.split('&')[3],\n",
    "))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
